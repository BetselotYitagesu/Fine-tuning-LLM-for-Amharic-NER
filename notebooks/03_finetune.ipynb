{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10634be1",
   "metadata": {},
   "source": [
    "3: Fine Tune NER Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025163d3",
   "metadata": {},
   "source": [
    "# Step 1: Environment Setup\n",
    "!pip install -q transformers datasets seqeval accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeedd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Upload & Parse the Dataset.\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the uploaded CoNLL file\n",
    "def parse_conll_file(filepath):\n",
    "    tokens = []\n",
    "    ner_tags = []\n",
    "\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        temp_tokens = []\n",
    "        temp_tags = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if temp_tokens:\n",
    "                    tokens.append(temp_tokens)\n",
    "                    ner_tags.append(temp_tags)\n",
    "                    temp_tokens, temp_tags = [], []\n",
    "            else:\n",
    "                splits = line.split()\n",
    "                if len(splits) >= 2:\n",
    "                    temp_tokens.append(splits[0])\n",
    "                    temp_tags.append(splits[1])\n",
    "        if temp_tokens:\n",
    "            tokens.append(temp_tokens)\n",
    "            ner_tags.append(temp_tags)\n",
    "\n",
    "    return {\"tokens\": tokens, \"ner_tags\": ner_tags}\n",
    "\n",
    "# uploaded wiht the right file name\n",
    "file_name = \"ner_auto_labels.conll\"\n",
    "data_dict = parse_conll_file(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90faf649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your labels based on your dataset\n",
    "label_list = [\"O\", \"B-PRODUCT\", \"I-PRODUCT\", \"B-PRICE\", \"I-PRICE\", \"B-LOC\", \"I-LOC\"]\n",
    "\n",
    "\n",
    "# Mappings\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenization and Label Alignment\n",
    "\n",
    "# Install & import the tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Davlan/xlm-roberta-base-ner-hrl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer and model loading code:\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc29357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tokenization + alignment function\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        current_word = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != current_word:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "                current_word = word_idx\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "\n",
    "        # pad labels to max_length (256)\n",
    "        label_ids += [-100] * (256 - len(label_ids))\n",
    "        label_ids = label_ids[:256]\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89649a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenizer and label alignment to your dataset\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d29ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique labels from the dataset\n",
    "all_labels = set()\n",
    "for tags in dataset[\"train\"][\"ner_tags\"]:\n",
    "    all_labels.update(tags)\n",
    "\n",
    "labels = sorted(all_labels)  # sorted list of unique labels\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training Arguments\n",
    "from transformers import TrainingArguments\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=[],  # <- disables logging to W&B and others\n",
    "    # Removed load_best_model_at_end and metric_for_best_model to avoid mismatch\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define metrics function for evaluation\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    # For token classification, predictions are logits, so take argmax\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_labels = [\n",
    "        [id_to_label[l] for l in label if l != -100]\n",
    "        for label in labels\n",
    "    ]\n",
    "    true_predictions = [\n",
    "        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Optionally, get overall metrics\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Initialize the Trainer and start training\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff18d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here is hte last Step\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b79a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation with the Trainer\n",
    "if eval_dataset is not None:\n",
    "    trainer.evaluate(eval_dataset=eval_dataset)\n",
    "else:\n",
    "    print(\"No evaluation dataset found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48088dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = \"./ner_model_amharic\"\n",
    "\n",
    "# Save model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
