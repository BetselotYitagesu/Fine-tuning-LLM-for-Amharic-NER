{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0644a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load Fine-Tuned Model\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_path = \"../models/xlm-roberta-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28f2426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Sample Sentence\n",
    "from datasets import Dataset\n",
    "sample = {\"tokens\": [\"ምጣድ\", \"ለፈጢራ\", \"በአነስተኛ\", \"ዋጋ\", \"በኤሌትሪክ\", \"ሀይል\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bec58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd0effae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set project root to Python path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.interpretability.interprete_model import explain_with_shap\n",
    "\n",
    "tokens = sample[\"tokens\"]  # list of tokens, e.g. ['በኤሌትሪክ', 'የሚሰራ', ...]\n",
    "shap_values = explain_with_shap(model, tokenizer, tokens)\n",
    "\n",
    "import shap\n",
    "shap.plots.text(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eddd5006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['ምጣድ', 'ለፈጢራ', 'በአነስተኛ', 'ዋጋ', 'በኤሌትሪክ']\n"
     ]
    }
   ],
   "source": [
    "print(type(tokens))\n",
    "print(tokens[:5])  # sample first 5 tokens\n",
    "\n",
    "assert isinstance(tokens, list)\n",
    "assert all(isinstance(t, str) for t in tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdd51f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = ['ምጣድ', 'ለፈጢራ', 'በአነስተኛ', 'ዋጋ', 'በኤሌትሪክ']\n",
    "# shap_values = explain_with_shap(model, tokenizer, tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c7c3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06bdc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scr.interpretability.interprete_model import explain_with_shap\n",
    "\n",
    "# shap_values = explain_with_shap(model, tokenizer, tokens)\n",
    "\n",
    "# import shap\n",
    "# shap.plots.text(shap_values[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and Save\n",
    "import shap\n",
    "shap.plots.text(shap_values[0], display=False)\n",
    "plt.savefig(\"../outputs/shap_explanation.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
